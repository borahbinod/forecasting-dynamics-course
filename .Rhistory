tmp = bison
tmp$year = tmp$year + 1
names(tmp)[2] = "lagN"
bison = full_join(bison,tmp)
bison = filter(bison,year > min(year) & year < max(year))  # drop incomplete observations
# add a column for log per capita growth rate
bison = mutate(bison, pgr = log(bison$N/bison$lagN))
# add log transformed variables
bison = mutate(bison, logN = log(N))
bison = mutate(bison, loglagN = log(lagN))
rm(tmp)
# Set up weather data ----------------------------------------------------
weather = read.csv("YNP_prism.csv", stringsAsFactors = FALSE)
weather = weather %>% separate(Date,c("year","month"), sep = '-')
weather$year = as.numeric(weather$year)
weather$month = as.numeric(weather$month)
weather$clim_year = ifelse(weather$month < 9, weather$year, weather$year + 1)
weather$clim_month = ifelse(weather$month < 9, weather$month + 4, weather$month - 8)
head(weather)
# To prepare for a merge with the bison data, we need to arrange months horizontally
# rather than vertically. Here is how to do it for the precip data:
precip_wide = weather %>%
select(c(clim_year,clim_month,ppt_in)) %>%  # drop all the other climate variables
spread(clim_month,ppt_in)
# rename months (optional, but I think it makes the data frame easier to understand)
names(precip_wide)[2:13] = paste0("ppt_",c("Sep","Oct","Nov","Dec","Jan","Feb","Mar","Apr","May","Jun","Jul","Aug"))
head(precip_wide)
# aggregate by season
precip_wide = mutate(precip_wide, ppt_Fall = rowSums(precip_wide[,c("ppt_Sep","ppt_Oct","ppt_Nov")]))
precip_wide = mutate(precip_wide, ppt_Win = rowSums(precip_wide[,c("ppt_Dec","ppt_Jan","ppt_Feb")]))
precip_wide = mutate(precip_wide, ppt_Spr = rowSums(precip_wide[,c("ppt_Mar","ppt_Apr","ppt_May")]))
precip_wide = mutate(precip_wide, ppt_Sum = rowSums(precip_wide[,c("ppt_Jun","ppt_Jul","ppt_Aug")]))
head(precip_wide)
# merge with bison
bison_wide = full_join(bison,precip_wide,by=c("year" = "clim_year"))
View(bison_wide)
bison_wide = left_join(bison,precip_wide,by=c("year" = "clim_year"))
head(bison_wide)
mbase <- lm(pgr ~ log(lagN), data=bison_wide )
summary(mbase)
mbase <- lm(logN ~ loglagN, data=bison_wide )
summary(mbase)
resids <- residuals(mbase)
resids
# scatter plots
my_plots=list()
for(i in 3:NCOL(bison_wide)){
tmp = data.frame(x=bison_wide[,i],resids=resids)
cors = cor.test(tmp$x,tmp$pgr)
my_plots[[i-2]] = ggplot(tmp, aes(x=x, y=pgr)) + geom_point() +
labs(x=names(bison_wide)[i],
title=paste("r = ",round(cors$estimate,3),", p =",round(cors$p.value,3)))
}
do.call(grid.arrange,my_plots)
head(bison_wide)
# scatter plots
my_plots=list()
for(i in 7:NCOL(bison_wide)){
tmp = data.frame(x=bison_wide[,i],resids=resids)
cors = cor.test(tmp$x,tmp$pgr)
my_plots[[i-2]] = ggplot(tmp, aes(x=x, y=pgr)) + geom_point() +
labs(x=names(bison_wide)[i],
title=paste("r = ",round(cors$estimate,3),", p =",round(cors$p.value,3)))
}
do.call(grid.arrange,my_plots)
# scatter plots
my_plots=list()
for(i in 7:NCOL(bison_wide)){
tmp = data.frame(x=bison_wide[,i],resids=resids)
cors = cor.test(tmp$x,tmp$pgr)
my_plots[[i-2]] = ggplot(tmp, aes(x=x, y=resids)) + geom_point() +
labs(x=names(bison_wide)[i],
title=paste("r = ",round(cors$estimate,3),", p =",round(cors$p.value,3)))
}
do.call(grid.arrange,my_plots)
mbase <- lm(logN ~ loglagN, data=bison_wide )
resids <- residuals(mbase)
tmp
# scatter plots
my_plots=list()
for(i in 7:NCOL(bison_wide)){
tmp = data.frame(x=bison_wide[,i],resids=resids)
cors = cor.test(tmp$x,tmp$resids)
my_plots[[i-2]] = ggplot(tmp, aes(x=x, y=resids)) + geom_point() +
labs(x=names(bison_wide)[i],
title=paste("r = ",round(cors$estimate,3),", p =",round(cors$p.value,3)))
}
do.call(grid.arrange,my_plots)
head(tmp)
ggplot(tmp, aes(x=x, y=resids)) + geom_point() +
labs(x=names(bison_wide)[i],
title=paste("r = ",round(cors$estimate,3),", p =",round(cors$p.value,3)))
head(bison_wide)
rm(list=ls())
#setwd("C:/Repos/forecasting-dynamics-course")
setwd("C:/Users/adler/Box Sync/teaching/Forecasting/private_code/model_selection")
library(forecast)
library(lubridate)
library(ggplot2)
library(dplyr)
library(tidyverse)
# Set up bison data -----------------------------------------------------
bison = read.csv("YNP_bison_counts.csv", stringsAsFactors = FALSE)
bison = select(bison,c(year,count.mean)) # drop non-essential columns
names(bison) = c("year","N") # rename columns
# the next few lines set up a lag N variable
tmp = bison
tmp$year = tmp$year + 1
names(tmp)[2] = "lagN"
bison = full_join(bison,tmp)
bison = filter(bison,year > min(year) & year < max(year))  # drop incomplete observations
# add a column for log per capita growth rate
bison = mutate(bison, pgr = log(bison$N/bison$lagN))
# add log transformed variables
bison = mutate(bison, logN = log(N))
bison = mutate(bison, loglagN = log(lagN))
rm(tmp)
# Set up weather data ----------------------------------------------------
weather = read.csv("YNP_prism.csv", stringsAsFactors = FALSE)
weather = weather %>% separate(Date,c("year","month"), sep = '-')
weather$year = as.numeric(weather$year)
weather$month = as.numeric(weather$month)
weather$clim_year = ifelse(weather$month < 9, weather$year, weather$year + 1)
weather$clim_month = ifelse(weather$month < 9, weather$month + 4, weather$month - 8)
head(weather)
# To prepare for a merge with the bison data, we need to arrange months horizontally
# rather than vertically. Here is how to do it for the precip data:
precip_wide = weather %>%
select(c(clim_year,clim_month,ppt_in)) %>%  # drop all the other climate variables
spread(clim_month,ppt_in)
# rename months (optional, but I think it makes the data frame easier to understand)
names(precip_wide)[2:13] = paste0("ppt_",c("Sep","Oct","Nov","Dec","Jan","Feb","Mar","Apr","May","Jun","Jul","Aug"))
head(precip_wide)
# aggregate by season
precip_wide = mutate(precip_wide, ppt_Fall = rowSums(precip_wide[,c("ppt_Sep","ppt_Oct","ppt_Nov")]))
precip_wide = mutate(precip_wide, ppt_Win = rowSums(precip_wide[,c("ppt_Dec","ppt_Jan","ppt_Feb")]))
precip_wide = mutate(precip_wide, ppt_Spr = rowSums(precip_wide[,c("ppt_Mar","ppt_Apr","ppt_May")]))
precip_wide = mutate(precip_wide, ppt_Sum = rowSums(precip_wide[,c("ppt_Jun","ppt_Jul","ppt_Aug")]))
head(precip_wide)
# merge with bison
bison_wide = left_join(bison,precip_wide,by=c("year" = "clim_year"))
# repeat spread, aggreate, merge with other climate var's as desired
###
### Model for exploration -------------------------------------
###
# let's get residuals from a baseline AR1 model (Gompertz)
mbase <- lm(logN ~ loglagN, data=bison_wide )
resids <- residuals(mbase)
# scatter plots
my_plots=list()
for(i in 7:NCOL(bison_wide)){
tmp = data.frame(x=bison_wide[,i],resids=resids)
cors = cor.test(tmp$x,tmp$resids)
my_plots[[i-2]] = ggplot(tmp, aes(x=x, y=resids)) + geom_point() +
labs(x=names(bison_wide)[i],
title=paste("r = ",round(cors$estimate,3),", p =",round(cors$p.value,3)))
}
do.call(grid.arrange,my_plots)
# scatter plots
my_plots=list()
for(i in 7:NCOL(bison_wide)){
tmp = data.frame(x=bison_wide[,i],resids=resids)
cors = cor.test(tmp$x,tmp$resids)
my_plots[[i-6]] = ggplot(tmp, aes(x=x, y=resids)) + geom_point() +
labs(x=names(bison_wide)[i],
title=paste("r = ",round(cors$estimate,3),", p =",round(cors$p.value,3)))
}
do.call(grid.arrange,my_plots)
rm(list=ls())
#setwd("C:/Repos/forecasting-dynamics-course")
setwd("C:/Users/adler/Box Sync/teaching/Forecasting/private_code/model_selection")
library(forecast)
library(lubridate)
library(ggplot2)
library(dplyr)
library(tidyverse)
# Set up bison data -----------------------------------------------------
bison = read.csv("YNP_bison_counts.csv", stringsAsFactors = FALSE)
bison = select(bison,c(year,count.mean)) # drop non-essential columns
names(bison) = c("year","N") # rename columns
# the next few lines set up a lag N variable
tmp = bison
tmp$year = tmp$year + 1
names(tmp)[2] = "lagN"
bison = full_join(bison,tmp)
bison = filter(bison,year > min(year) & year < max(year))  # drop incomplete observations
# add log transformed variables
bison = mutate(bison, logN = log(N))
bison = mutate(bison, loglagN = log(lagN))
rm(tmp)
# Set up weather data ----------------------------------------------------
weather = read.csv("YNP_prism.csv", stringsAsFactors = FALSE)
weather = weather %>% separate(Date,c("year","month"), sep = '-')
weather$year = as.numeric(weather$year)
weather$month = as.numeric(weather$month)
weather$clim_year = ifelse(weather$month < 9, weather$year, weather$year + 1)
weather$clim_month = ifelse(weather$month < 9, weather$month + 4, weather$month - 8)
head(weather)
# To prepare for a merge with the bison data, we need to arrange months horizontally
# rather than vertically. Here is how to do it for the precip data:
precip_wide = weather %>%
select(c(clim_year,clim_month,ppt_in)) %>%  # drop all the other climate variables
spread(clim_month,ppt_in)
# rename months (optional, but I think it makes the data frame easier to understand)
names(precip_wide)[2:13] = paste0("ppt_",c("Sep","Oct","Nov","Dec","Jan","Feb","Mar","Apr","May","Jun","Jul","Aug"))
head(precip_wide)
# aggregate by season
precip_wide = mutate(precip_wide, ppt_Fall = rowSums(precip_wide[,c("ppt_Sep","ppt_Oct","ppt_Nov")]))
precip_wide = mutate(precip_wide, ppt_Win = rowSums(precip_wide[,c("ppt_Dec","ppt_Jan","ppt_Feb")]))
precip_wide = mutate(precip_wide, ppt_Spr = rowSums(precip_wide[,c("ppt_Mar","ppt_Apr","ppt_May")]))
precip_wide = mutate(precip_wide, ppt_Sum = rowSums(precip_wide[,c("ppt_Jun","ppt_Jul","ppt_Aug")]))
head(precip_wide)
# merge with bison
bison_wide = left_join(bison,precip_wide,by=c("year" = "clim_year"))
# repeat spread, aggreate, merge with other climate var's as desired
###
### Model for exploration -------------------------------------
###
# let's get residuals from a baseline AR1 model (Gompertz)
mbase <- lm(logN ~ loglagN, data=bison_wide )
resids <- residuals(mbase)
# scatter plots
my_plots=list()
for(i in 6:NCOL(bison_wide)){
tmp = data.frame(x=bison_wide[,i],resids=resids)
cors = cor.test(tmp$x,tmp$resids)
my_plots[[i-6]] = ggplot(tmp, aes(x=x, y=resids)) + geom_point() +
labs(x=names(bison_wide)[i],
title=paste("r = ",round(cors$estimate,3),", p =",round(cors$p.value,3)))
}
do.call(grid.arrange,my_plots)
# do any scatters look significant? can you test for that? would accounting for
# density dependence help?
rm(list=ls())
#setwd("C:/Repos/forecasting-dynamics-course")
setwd("C:/Users/adler/Box Sync/teaching/Forecasting/private_code/model_selection")
library(forecast)
library(lubridate)
library(ggplot2)
library(dplyr)
library(tidyverse)
# Set up bison data -----------------------------------------------------
bison = read.csv("YNP_bison_counts.csv", stringsAsFactors = FALSE)
bison = select(bison,c(year,count.mean)) # drop non-essential columns
names(bison) = c("year","N") # rename columns
# the next few lines set up a lag N variable
tmp = bison
tmp$year = tmp$year + 1
names(tmp)[2] = "lagN"
bison = full_join(bison,tmp)
bison = filter(bison,year > min(year) & year < max(year))  # drop incomplete observations
# add log transformed variables
bison = mutate(bison, logN = log(N))
bison = mutate(bison, loglagN = log(lagN))
rm(tmp)
# Set up weather data ----------------------------------------------------
weather = read.csv("YNP_prism.csv", stringsAsFactors = FALSE)
weather = weather %>% separate(Date,c("year","month"), sep = '-')
weather$year = as.numeric(weather$year)
weather$month = as.numeric(weather$month)
weather$clim_year = ifelse(weather$month < 9, weather$year, weather$year + 1)
weather$clim_month = ifelse(weather$month < 9, weather$month + 4, weather$month - 8)
head(weather)
# To prepare for a merge with the bison data, we need to arrange months horizontally
# rather than vertically. Here is how to do it for the precip data:
precip_wide = weather %>%
select(c(clim_year,clim_month,ppt_in)) %>%  # drop all the other climate variables
spread(clim_month,ppt_in)
# rename months (optional, but I think it makes the data frame easier to understand)
names(precip_wide)[2:13] = paste0("ppt_",c("Sep","Oct","Nov","Dec","Jan","Feb","Mar","Apr","May","Jun","Jul","Aug"))
head(precip_wide)
# aggregate by season
precip_wide = mutate(precip_wide, ppt_Fall = rowSums(precip_wide[,c("ppt_Sep","ppt_Oct","ppt_Nov")]))
precip_wide = mutate(precip_wide, ppt_Win = rowSums(precip_wide[,c("ppt_Dec","ppt_Jan","ppt_Feb")]))
precip_wide = mutate(precip_wide, ppt_Spr = rowSums(precip_wide[,c("ppt_Mar","ppt_Apr","ppt_May")]))
precip_wide = mutate(precip_wide, ppt_Sum = rowSums(precip_wide[,c("ppt_Jun","ppt_Jul","ppt_Aug")]))
head(precip_wide)
# merge with bison
bison_wide = left_join(bison,precip_wide,by=c("year" = "clim_year"))
# repeat spread, aggreate, merge with other climate var's as desired
###
### Model for exploration -------------------------------------
###
# let's get residuals from a baseline AR1 model (Gompertz)
mbase <- lm(logN ~ loglagN, data=bison_wide )
resids <- residuals(mbase)
# scatter plots
my_plots=list()
for(i in 6:NCOL(bison_wide)){
tmp = data.frame(x=bison_wide[,i],resids=resids)
cors = cor.test(tmp$x,tmp$resids)
my_plots[[i-5]] = ggplot(tmp, aes(x=x, y=resids)) + geom_point() +
labs(x=names(bison_wide)[i],
title=paste("r = ",round(cors$estimate,3),", p =",round(cors$p.value,3)))
}
do.call(grid.arrange,my_plots)
# do any scatters look significant? can you test for that? would accounting for
# density dependence help?
library(climwin)
bison$Date = as_date(paste(bison$year, "08", "01"))
weather$Date = as_date(paste(weather$year,weather$month,"15"))
bisonWin <- slidingwin(xvar = list(ppt = weather$ppt_in),
cdate = weather$Date,
bdate = bison$Date,
baseline = lm(logN ~ loglagN, data = bison),
range = c(12, 0),
type = "relative", stat = "sum",
func = c("lin"), cmissing = FALSE, cinterval = "month")
bisonWin$combos
summary(bisonWin[[1]]$BestModel)
m = lm(logN ~ loglagN + ppt_Win, data=bison_wide )
summary(m)
library(climwin)
library(lubridate)
head(bison_wide)
keep <- "loglagN"
keep <- c(keep, names(bison_wide)[grep(bison_wide,"ppt")] )
keep <- "loglagN"
keep <- c(keep, names(bison_wide)[grep("ppt",bison_wide)] )
keep
keep <- "loglagN"
keep <- c(keep, grep("ppt",names(bison_wide) )
X <- as.matrix(select(bison_wide, imp_vars)) # covariate matrix
# Make sure there are no NAs in the covariate matrix
test_vec <- as.numeric(apply(X, MARGIN = 2, FUN = "mean"))
nacols <- which(is.na(test_vec))
if(length(nacols) > 0) X <- X[,-nacols]
# Standaradize the covariate values
X <- scale(X, center = TRUE, scale = TRUE)
# Run ridge regression ---------------------------------------------------------
pen_facts <- rep(1, ncol(X)) # penalize all covariates
lambdas <- 10^seq(2, -2, by = -.005) # sequence of penalties to test
ridge_out <- cv.glmnet(x = X,
y = y,
lambda = lambdas,
penalty.factor = pen_facts,
family = "gaussian",
alpha = 0, # 0 for ridge, 1 for lasso, 0.5 for elastic net
standardize = FALSE,
type.measure = "mse", # mean square error
nfolds = 6) # for cross-validation
keep
keep <- c(keep, grep("ppt",names(bison_wide)) )
keep
?grp
?grep
keep <- "loglagN"
keep <- c(keep, grep("ppt",names(bison_wide),value=T) )
keep
X <- as.matrix(select(bison_wide, keep)) # covariate matrix
head(X)
sum(is.na(X))
test_vec <- as.numeric(apply(X, MARGIN = 2, FUN = "mean"))
nacols <- which(is.na(test_vec))
if(length(nacols) > 0) X <- X[,-nacols]
X <- scale(X, center = TRUE, scale = TRUE)
library(glmnet) # package for statistical regularization
?glmnet
head(X)
pen_facts <- c(0,rep(1, ncol(X)-1)) # penalize all covariates EXCEPT loglagN
dim(Z)
dim(X)
length(pen_facts)
# Prepare data for glmnet ------------------------------------------------------
y <- bison_wide$logN # population growth rate
covar_names <- c("loglagN", grep("ppt",names(bison_wide),value=T) )
X <- as.matrix(select(bison_wide, covar_names)) # covariate matrix
# Make sure there are no NAs in the covariate matrix
test_vec <- as.numeric(apply(X, MARGIN = 2, FUN = "mean"))
nacols <- which(is.na(test_vec))
if(length(nacols) > 0) X <- X[,-nacols]
# Standaradize the covariate values
X <- scale(X, center = TRUE, scale = TRUE)
# Run ridge regression ---------------------------------------------------------
pen_facts <- c(0,rep(1, ncol(X)-1)) # penalize all covariates EXCEPT the first, loglagN
lambdas <- 10^seq(2, -2, by = -.005) # sequence of penalties to test
ridge_out <- cv.glmnet(x = X,
y = y,
lambda = lambdas,
penalty.factor = pen_facts,
family = "gaussian",
alpha = 0, # 0 for ridge, 1 for lasso, 0.5 for elastic net
standardize = FALSE,
type.measure = "mse", # mean square error
nfolds = 6) # for cross-validation
plot(ridge_out)
best_coefs <- ridge_out$beta[,which(ridge_out$lambda==ridge_out$lambda.min)]
best_coefs
ridge_out$beta
ridge_out <- cv.glmnet(x = X,
y = y,
lambda = lambdas,
penalty.factor = pen_facts,
family = "gaussian",
alpha = 0, # 0 for ridge, 1 for lasso, 0.5 for elastic net
standardize = FALSE,
type.measure = "mse", # mean square error
nfolds = 6) # for cross-validation
ridge_out$beta
best_coefs <- ridge_out$glmnet.fit$beta[,which(ridge_out$lambda==ridge_out$lambda.min)]
best_coefs
plotbetas(ridge_out)
plot(ridge_out)
ridge_out <- cv.glmnet(x = X,
y = y,
lambda = lambdas,
penalty.factor = pen_facts,
family = "gaussian",
alpha = 0, # 0 for ridge, 1 for lasso, 0.5 for elastic net
standardize = FALSE,
type.measure = "mse", # mean square error
nfolds = 6) # for cross-validation
plot(ridge_out)
plotCoef(ridge_out)
?plotCoef
plot.coef.glmnet(ridge_out
)
matplot(ridge_out$glmnet.fit)
matplot(ridge_out$glmnet.fit$betas)
matplot(ridge_out$glmnet.fit$beta)
matplot(ridge_out$glmnet.fit$beta,type="l")
ridge_preds <- predict(ridge_out, newx=X,s="lambda.min")
plot(y,ridge_preds)
null_preds = predict(lm(y, X[,1]))
null_preds = predict(lm(y ~ X[,1]))
plot(y,null_preds)
ridge_out <- cv.glmnet(x = X,
y = y,
lambda = lambdas,
penalty.factor = pen_facts,
family = "gaussian",
alpha = 1, # 0 for ridge, 1 for lasso, 0.5 for elastic net
standardize = FALSE,
type.measure = "mse", # mean square error
nfolds = 6) # for cross-validation
best_coefs <- ridge_out$glmnet.fit$beta[,which(ridge_out$lambda==ridge_out$lambda.min)]
best_coefs
plot(ridge_out)
# predictions for training data WITH climate variables
clim_preds = predict(ridge_out, newx=X,s="lambda.min")
# predictions from a null model (no climate variables)
null_preds = predict(lm(y ~ X[,1]))
# compare MAE
print(paste("MAE climate =",abs(clime_preds - y)))
print(paste("MAE climate =",abs(null_preds - y)))
print(paste("MAE climate =",mean(abs(clime_preds - y))))
print(paste("MAE climate =",mean(abs(clim_preds - y))))
print(paste("MAE climate =",mean(abs(null_preds - y))))
p1 <- ggplot(aes(x=y,y=clim_preds)) + geom_point() + lab(x = "Observed",y="Clim. preds.")
p1 <- ggplot(data=cbind(y,clim_preds),aes(x=y,y=clim_preds)) + geom_point() + lab(x = "Observed",y="Clim. preds.")
p1 <- ggplot(data=data.frame(y,clim_preds),aes(x=y,y=clim_preds)) + geom_point() + lab(x = "Observed",y="Clim. preds.")
p1 <- ggplot(data=data.frame(y,clim_preds),aes(x=y,y=clim_preds)) + geom_point() + labs(x = "Observed",y="Clim. preds.")
p1
p2 <- ggplot(data=data.frame(y,null_preds),aes(x=y,y=null_preds)) + geom_point() + labs(x = "Observed",y="Clim. preds.")
p2
grid.arrange(p1,p2)
p1 <- ggplot(data=data.frame(y,clim_preds),aes(x=y,y=clim_preds)) + geom_point() + labs(x = "Observed",y="Clim. preds.")
p2 <- ggplot(data=data.frame(y,null_preds),aes(x=y,y=null_preds)) + geom_point() + labs(x = "Observed",y="Null. preds.")
grid.arrange(p1,p2)
print(best_coefs)
ridge_out <- cv.glmnet(x = X,
y = y,
lambda = lambdas,
penalty.factor = pen_facts,
family = "gaussian",
alpha = 0, # 0 for ridge, 1 for lasso, 0.5 for elastic net
standardize = FALSE,
type.measure = "mse", # mean square error
nfolds = 6) # for cross-validation
best_coefs = ridge_out$glmnet.fit$beta[,which(ridge_out$lambda==ridge_out$lambda.min)]
print(best_coefs)
barplot(best_coefs)
barplot(log(best_coefs))
barplot(sqrt(best_coefs))
barplot(best_coefs[2:length(best_coefs)])
source('C:/Users/adler/Box Sync/teaching/Forecasting/private_code/model_selection/model-selection-assignment-answers-YNP-bison.R')
source('C:/Users/adler/Box Sync/teaching/Forecasting/private_code/model_selection/model-selection-assignment-answers-YNP-bison.R')
source('C:/Users/adler/Box Sync/teaching/Forecasting/private_code/model_selection/model-selection-assignment-answers-YNP-bison.R')
source('C:/Users/adler/Box Sync/teaching/Forecasting/private_code/model_selection/model-selection-assignment-answers-YNP-bison.R')
lasso_out <- cv.glmnet(x = X,
y = y,
lambda = lambdas,
penalty.factor = pen_facts,
family = "gaussian",
alpha = 1, # 0 for ridge, 1 for lasso, 0.5 for elastic net
standardize = FALSE,
type.measure = "mse", # mean square error
nfolds = 6) # for cross-validation
best_coefs = lasso_out$glmnet.fit$beta[,which(lasso_out$lambda==lasso_out$lambda.min)]
print(lasso_out)
print(best_coefs)
head(x)
head(X)
my_glm = lm(y~ loglagN + ppt_Dec + ppt_Jan + ppt_Feb + ppt_Mar + ppt_Apr + ppt_Jul,data=X )
is.matrix(X)
my_glm = lm(y~ loglagN + ppt_Dec + ppt_Jan + ppt_Feb + ppt_Mar + ppt_Apr + ppt_Jul,
data = as.data.drame(X))
my_glm = lm(y~ loglagN + ppt_Dec + ppt_Jan + ppt_Feb + ppt_Mar + ppt_Apr + ppt_Jul,
data = as.data.frame(X))
summary(my_glm)
print(best_coefs)
plot(coefs(my_glm)[2:length(coefs(my_glm))])
plot(coef(my_glm)[2:length(coef(my_glm))])
plot(coef(my_glm)[2:length(coef(my_glm))],best_coefs[best_coefs>0])
best_coefs[best_coefs > 0]
plot(coef(my_glm)[2:length(coef(my_glm))],best_coefs[abs(best_coefs)>0])
plot(coef(my_glm)[3:length(coef(my_glm))],best_coefs[abs(best_coefs)>0 & best_coefs < 0.5])
abline(0,1)
plot(coef(my_glm)[3:length(coef(my_glm))],best_coefs[abs(best_coefs)>0 & best_coefs < 0.5],
xlab="lm",ylab="LASSO")
abline(0,1)
NDVI = read.csv('./../data/portal_timeseries.csv', stringsAsFactors = FALSE)
